{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZrkmpkW8Wbj"
   },
   "source": [
    "# Part-1 : Section A\n",
    "Training a multi-exit ElasticBERT model on SST-2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CkfzdLG9C1T",
    "outputId": "a7400ed9-42af-4197-ba5e-a1b1bb03fa34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/divya/UBERT/MutiExitDNNs/ElasticBERT'\n",
      "/home/aix7101/jeong/CeeBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aix7101/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "# The code closely follows the original ElasticBERT repository\n",
    "# Feature to train models with a given exit configuration is added\n",
    "# !git clone https://github.com/MLiONS/MutiExitDNNs.git\n",
    "\n",
    "\n",
    "%cd /home/divya/UBERT/MutiExitDNNs/ElasticBERT\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aix7101/jeong/CeeBERT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A26ZgAoxPyiJ",
    "outputId": "93510bc8-6217-4989-c9e9-24beef747003"
   },
   "outputs": [],
   "source": [
    "#All the hyper-parameters/ location to training dataset are set in\n",
    "#MultiExitDNNs -> finetune-dynamic -> finetune_elue_entropy.sh file\n",
    "\n",
    "#1)Set the correct location to SST-2 dataset\n",
    "#All models are trained on SST-2 \"train\" split and evaluated on \"dev\" split\n",
    "#\"train.tsv\" and \"dev.tsv\" are expected to be in ELUE_DIR/TASK_NAME\n",
    "#You can set both ELUE_DIR and TASK_NAME in finetune_elue_entropy.sh\n",
    "#Or change the dataset directory using \"data_dir\" option\n",
    "\n",
    "#2)Please change the \"num_output_layers\" option as per the desired exit-configuration\n",
    "\n",
    "#3)Model checkpoints will be saved at \"output_dir\" and\n",
    "#logs will be available at \"log_dir\"\n",
    "# bash finetune_elue_entropy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tfcWxU28kkl"
   },
   "source": [
    "# Part-1 : Section B\n",
    "Generating the prediction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "acoXLlG2y1ty"
   },
   "outputs": [],
   "source": [
    "#Evaluation on other datasets-IMDb or Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aix7101/jeong/CeeBERT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aix7101/jeong/CeeBERT/ElasticBERT/finetune-dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aix7101/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ElasticBERT/finetune-dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kb9mBUI5y1q-",
    "outputId": "f06bf2bb-9a73-407f-b80d-8b5064d1cc1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aix7101/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer as ElasticBertTokenizer\n",
    "\n",
    "#Set the current directory location inside \"finetune-dynamic\" folder\n",
    "# cd /home/divya/UBERT/MutiExitDNNs/ElasticBERT/finetune-dynamic\n",
    "\n",
    "from models.configuration_elasticbert import ElasticBertConfig\n",
    "from models.modeling_elasticbert_entropy import ElasticBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/aix7101/jeong/fnlp/elasticbert-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZkT2IrL2b90d"
   },
   "outputs": [],
   "source": [
    "#Set location to the best performing model\n",
    "#Model checkpoints are saved at \"output_dir\" from Part-1: Section A\n",
    "checkpoint_snli = path + '/ckpts/elue/entropy/SNLI/checkpoint-25700'\n",
    "checkpoint_sst = path + '/ckpts/elue/entropy/SST-2/checkpoint-300'\n",
    "checkpoint_mrpc = path + '/ckpts/elue/entropy/MRPC/checkpoint-575'\n",
    "checkpoint_scitail = path + '/ckpts/elue/entropy/SciTail/checkpoint-3690'\n",
    "checkpoint_rte = path + '/ckpts/elue/entropy/RTE/checkpoint-390'\n",
    "checkpoint_mnli = path + '/ckpts/elue/entropy/MNLI/checkpoint-61360'\n",
    "checkpoint_qnli = path + '/ckpts/elue/entropy/QNLI/checkpoint-16370'\n",
    "checkpoint_qqp = path + '/ckpts/elue/entropy/QQP/checkpoint-56855'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cCv-3N0CaM0s"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aix7101/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/transformers/modeling_utils.py:1205: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "config = ElasticBertConfig.from_pretrained(checkpoint_sst)\n",
    "tokenizer = ElasticBertTokenizer.from_pretrained(checkpoint_sst)\n",
    "model = ElasticBertForSequenceClassification.from_pretrained(checkpoint_sst)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AFt7llc_g130"
   },
   "outputs": [],
   "source": [
    "def get_args(arg_vec):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Required parameters\n",
    "    parser.add_argument(\n",
    "        \"--num_hidden_layers\",\n",
    "        default=None,\n",
    "        type=int,\n",
    "        required=True,\n",
    "        help='The number of layers to import.',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_output_layers\",\n",
    "        nargs = 12,\n",
    "        default=None,\n",
    "        type=int,\n",
    "        required=True,\n",
    "        help='The number of layers to output.',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_dir\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_or_path\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to pre-trained model or shortcut name.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--task_name\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The name of the task to train selected in the list.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--log_dir\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The output directory where the logs will be written.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--spec_eval\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=False,\n",
    "        help=\"'Set as train or test based on specific split on which to evaluate'\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--patience\",\n",
    "        default='0',\n",
    "        type=str,\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--regression_threshold\",\n",
    "        default=0,\n",
    "        type=float,\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--early_exit_entropy\",\n",
    "        default='0.1',\n",
    "        type=str,\n",
    "        required=False,\n",
    "    )\n",
    "    # Other parameters\n",
    "    parser.add_argument(\n",
    "        \"--load\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        help=\"The path of ckpts used to continue training.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--config_name\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"Pretrained config name or path if not the same as model_name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--tokenizer_name\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cache_dir\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"Where do you want to store the pre-trained models downloaded from huggingface.co\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_seq_length\",\n",
    "        default=128,\n",
    "        type=int,\n",
    "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "             \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", help=\"Whether to use debug mode.\")\n",
    "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
    "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
    "    parser.add_argument(\n",
    "        \"--evaluate_during_training\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Run evaluation during training at each logging step.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--do_lower_case\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Set this flag if you are using an uncased model.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_gpu_train_batch_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU/CPU for training.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_gpu_eval_batch_size\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"Batch size per GPU/CPU for evaluation.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        default=5e-5,\n",
    "        type=float,\n",
    "        help=\"The initial learning rate for Adam.\",\n",
    "    )\n",
    "    parser.add_argument(\"--weight_decay\", default=0.01, type=float, help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\n",
    "        \"--num_train_epochs\",\n",
    "        default=3.0,\n",
    "        type=float,\n",
    "        help=\"Total number of training epochs to perform.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_steps\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
    "    )\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument(\"--warmup_rate\", default=0, type=float, help=\"Linear warmup over warmup_rate.\")\n",
    "\n",
    "    parser.add_argument(\"--logging_steps\", type=int, default=500, help=\"Log every X updates steps.\")\n",
    "    parser.add_argument(\n",
    "        \"--save_steps\",\n",
    "        type=int,\n",
    "        default=500,\n",
    "        help=\"Save checkpoint every X updates steps.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_all_checkpoints\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
    "    )\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_output_dir\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Overwrite the content of the output directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_cache\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Overwrite the cached training and evaluation sets\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--not_save_model\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Do not save model checkpoints\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", type=int, default=6, help=\"random seed for initialization\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--fp16\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fp16_opt_level\",\n",
    "        type=str,\n",
    "        default=\"O1\",\n",
    "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "             \"See details at https://nvidia.github.io/apex/amp.html\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--local_rank\",\n",
    "        type=int,\n",
    "        default=-1,\n",
    "        help=\"For distributed training: local_rank\",\n",
    "    )\n",
    "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
    "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
    "    args = parser.parse_args(arg_vec)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.config.num_labels = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"model.config.num_labels =\", model.config.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- loss 계산을 위해 num_labels를 task에 맞춰서 변경해줘야함\n",
    "model.config.num_labels = 3\n",
    "model.classifier = torch.nn.Linear(model.config.hidden_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.config.num_labels = 3\n"
     ]
    }
   ],
   "source": [
    "print(\"model.config.num_labels =\", model.config.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "E2cX_ym5pJwl"
   },
   "outputs": [],
   "source": [
    "from load_data import (\n",
    "    load_and_cache_examples_glue,\n",
    "    load_and_cache_examples_elue,\n",
    ")\n",
    "\n",
    "def evaluate_elue_entropy(args, model, tokenizer, prefix=\"\", eval_highway=False, entropy=0.):\n",
    "    model.elasticbert.set_early_exit_entropy(entropy)\n",
    "    model.elasticbert.set_eval_state(eval_highway)\n",
    "    model.elasticbert.reset_stats()\n",
    "\n",
    "    eval_task = args.task_name.lower()\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    num_op_layers = args.num_output_layers\n",
    "\n",
    "    results = {}\n",
    "    results_all = []\n",
    "    exit_layer = []\n",
    "    for i in range(sum(num_op_layers)):\n",
    "        results_all.append({})\n",
    "\n",
    "    if args.spec_eval:\n",
    "      eval_dataset = load_and_cache_examples_elue(args, eval_task, tokenizer, data_type=args.spec_eval)\n",
    "    else:\n",
    "      eval_dataset = load_and_cache_examples_elue(args, eval_task, tokenizer, data_type='train')\n",
    "\n",
    "    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    # multi-gpu eval\n",
    "    if args.n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    preds_all = []\n",
    "    pred_tuple = []\n",
    "    for i in range(sum(num_op_layers)):\n",
    "        preds_all.append(None)\n",
    "        pred_tuple.append(None)\n",
    "    out_label_ids = None\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        labels = batch[-1]\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"labels\": batch[-1],\n",
    "            }\n",
    "            inputs[\"token_type_ids\"] = batch[2]\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if out_label_ids is None:\n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "        if not eval_highway:\n",
    "            for i, pred in enumerate(preds_all):\n",
    "                if pred is None:\n",
    "                    preds_all[i] = logits[i].detach().cpu().numpy()\n",
    "                else:\n",
    "                    preds_all[i] = np.append(pred, logits[i].detach().cpu().numpy(), axis=0)\n",
    "        else:\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args.output_mode == \"classification\":\n",
    "        if not eval_highway:\n",
    "            for i, pred in enumerate(preds_all):\n",
    "                preds_all[i] = np.argmax(pred, axis = 1)\n",
    "                pred_tuple[i] = pred\n",
    "        else:\n",
    "            preds = np.argmax(preds, axis = 1)\n",
    "            pred_tuple[i] = pred\n",
    "\n",
    "    elif args.output_mode == \"regression\":\n",
    "        if not eval_highway:\n",
    "            for i, pred in enumerate(preds_all):\n",
    "                preds_all[i] = np.squeeze(pred)\n",
    "        else:\n",
    "            preds = np.squeeze(preds)\n",
    "\n",
    "    if not eval_highway:\n",
    "        for i, pred in enumerate(preds_all):\n",
    "            if eval_task == 'rte' or 'qnli' or 'wnli' or 'qqp':\n",
    "                eval_task = 'scitail'\n",
    "            if eval_task == 'mnli':\n",
    "                eval_task = 'snli'\n",
    "            if eval_task == 'yelp':\n",
    "              eval_task = 'imdb'\n",
    "            result = elue_compute_metrics(eval_task, pred, out_label_ids)\n",
    "            results_all[i].update(result)\n",
    "\n",
    "    else:\n",
    "        if eval_task == 'rte' or 'qnli' or 'wnli' or 'qqp':\n",
    "                eval_task = 'scitail'\n",
    "        if eval_task == 'mnli':\n",
    "                eval_task = 'snli'\n",
    "        result = elue_compute_metrics(eval_task, preds, out_label_ids)\n",
    "        results.update(result)\n",
    "\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            print(\"  %s = %s\" % (key, str(result[key])))\n",
    "\n",
    "        exiting_layer_every_ins = model.elasticbert.exiting_layer_every_ins\n",
    "        exit_layer.append(exiting_layer_every_ins)\n",
    "\n",
    "    if eval_highway:\n",
    "        speed_up = model.elasticbert.log_stats()\n",
    "        return results, speed_up, exit_layer\n",
    "\n",
    "    if args.spec_eval:\n",
    "      return results_all, preds_all, pred_tuple, out_label_ids\n",
    "\n",
    "    return results_all, preds_all, pred_tuple , out_label_ids\n",
    "    #return results_all, preds_all, out_label_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jCJmL5-yez21"
   },
   "outputs": [],
   "source": [
    "ELUE_DIR='/mnt/aix7101/jeong/fnlp/elasticbert-base'\n",
    "TASK_NAME='SST-2'\n",
    "\n",
    "arg_vec= ['--model_name_or_path', 'fnlp/elasticbert-base',\n",
    "  '--task_name', 'SST-2', \\\n",
    "  '--do_train', \\\n",
    "  '--do_lower_case', \\\n",
    "  '--data_dir', \"/home/divya/UBERT/elue_data\", \\\n",
    "  '--log_dir', '/mnt/aix7101/jeong/fnlp/elasticbert-base/log/elue/entropy/SNLI-BTestCheck', \\\n",
    "  '--output_dir', '/mnt/aix7101/jeong/fnlp/elasticbert-base/ckpts/elue/entropy/SNLI-BTestCheck', \\\n",
    "  '--num_hidden_layers', '12', \\\n",
    "  '--num_output_layers', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', \\\n",
    "  '--max_seq_length', '128', \\\n",
    "  '--per_gpu_train_batch_size', '32', \\\n",
    "  '--per_gpu_eval_batch_size',' 32', \\\n",
    "  '--learning_rate', '2e-5', \\\n",
    "  '--weight_decay', '0.1', \\\n",
    "  '--save_steps', '50', \\\n",
    "  '--logging_steps', '50', \\\n",
    "  '--num_train_epochs', '5',  \\\n",
    "  '--warmup_rate', '0.06', \\\n",
    "  '--evaluate_during_training', \\\n",
    "  '--overwrite_output_dir'\n",
    "]\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "args = get_args(arg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLZpjqakoP9G",
    "outputId": "a9b77e92-8aaf-4f06-db5f-b87dd9aec42c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    args.n_gpu = 1\n",
    "args.device = device\n",
    "\n",
    "args.output_mode = 'classification'\n",
    "\n",
    "print(args.device)\n",
    "model.to(args.device)\n",
    "print(args.n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "50EjaE5MhPkU"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/hsm207/imdb_data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lfKacfaChWSJ"
   },
   "outputs": [],
   "source": [
    "# %cd imdb_data\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YsgrccgxiiQq"
   },
   "outputs": [],
   "source": [
    "# !tf_upgrade_v2 --infile create_imdb_dataset.py --outfile bar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vbLkqld8ipqI"
   },
   "outputs": [],
   "source": [
    "# !python bar.py --output_dir /home/divya/UBERT/elue_data/imdb_data/imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rNSuHnH-mSPt"
   },
   "outputs": [],
   "source": [
    "#Custom Selection\n",
    "# dataset = 'SNLI'#'IMDb' #or 'Yelp'\n",
    "# data_split = 'train'\n",
    "#To check model performance on SST-2 dev split:\n",
    "#Please set dataset = 'SST-2' and data_split='dev'\n",
    "dataset = 'SST-2'\n",
    "data_split='dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZyrFjs52hwRW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_preds(eval_dataset='SNLI', data_split='train'):\n",
    "  args.spec_eval = False\n",
    "  args.task_name = eval_dataset.lower()\n",
    "  args.data_dir=ELUE_DIR + '/'+args.task_name\n",
    "\n",
    "  results_all, exit_preds, pred_tuple, op_labels = evaluate_elue_entropy(args, model, tokenizer)\n",
    "\n",
    "\n",
    "  # exit_preds_list = np.stack(exit_preds, axis=1)\n",
    "  # df = pd.DataFrame((exit_preds_list) )\n",
    "  # df['op_labels'] = op_labels\n",
    "\n",
    "  return  results_all, exit_preds, pred_tuple, op_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # 1. SNLI 데이터셋 불러오기\n",
    "# dataset = load_dataset(\"snli\", split=\"train\")\n",
    "\n",
    "# # 2. 사용할 컬럼만 선택 (라벨이 유효한 것만 필터링)\n",
    "# filtered = dataset.filter(lambda x: x['label'] != -1)\n",
    "\n",
    "# # 3. 데이터프레임으로 변환\n",
    "# df = pd.DataFrame({\n",
    "#     \"premise\": filtered[\"premise\"],\n",
    "#     \"hypothesis\": filtered[\"hypothesis\"],\n",
    "#     \"label\": filtered[\"label\"]\n",
    "# })\n",
    "\n",
    "# # 4. 저장 경로 설정\n",
    "# save_dir = \"/mnt/aix7101/jeong/fnlp/elasticbert-base/snli\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# save_path = os.path.join(save_dir, \"train.tsv\")\n",
    "\n",
    "# # 5. TSV 파일로 저장\n",
    "# df.to_csv(save_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# print(f\"✅ Saved SNLI train.tsv to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미 모델을 GPU에 올린 적이 있으면 해당 데이터에서 에러가 날 수 있으므로 아예 restart하는 것도 좋은 방법임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxJkyv_xHy-H",
    "outputId": "e676791a-51ed-49db-a84a-6e2a00c290e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aix7101/jeong/CeeBERT/ElasticBERT/finetune-dynamic/load_data.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(cached_features_file)\n",
      "Evaluating: 100%|██████████| 2105/2105 [01:17<00:00, 27.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from elue import elue_compute_metrics\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "results, final_preds, pred_tuple, op_labels = get_preds(eval_dataset=dataset, data_split=data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67349"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(pred_tuple[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67349\n",
      "7\n",
      "67349\n"
     ]
    }
   ],
   "source": [
    "print(len(op_labels))\n",
    "print(len(final_preds))\n",
    "print(len(final_preds[0]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FnF4zrhPMYNV"
   },
   "outputs": [],
   "source": [
    "accurac_imd = []\n",
    "for j in range(sum(args.num_output_layers)):\n",
    "    accuracy = 0\n",
    "    for i in range(len(op_labels)):\n",
    "        if final_preds[j][i] == op_labels[i]:\n",
    "            accuracy+=1\n",
    "        else:\n",
    "            pass\n",
    "    accurac_imd.append(accuracy/len(op_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurac_yelp = []\n",
    "for j in range(sum(args.num_output_layers)):\n",
    "    accuracy = 0\n",
    "    for i in range(len(op_labels)):\n",
    "        if final_preds[j][i] == op_labels[i]:\n",
    "            accuracy+=1\n",
    "        else:\n",
    "            pass\n",
    "    accurac_yelp.append(accuracy/len(op_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6, 7]\n",
    "plt.plot(x, accurac_imd, linestyle='dotted', marker = '^', color=\"r\")\n",
    "plt.plot(x, accurac_yelp, linestyle='dotted', marker = 'o', color=\"g\")\n",
    "plt.xlabel(\"Layer number\", fontsize = 17)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 17)\n",
    "plt.title(\"Accuracy vs Layer\", fontsize = 17)\n",
    "plt.legend(['IMDb', 'Yelp'],\n",
    "        prop = {'size' : 15},\n",
    "        loc = 'lower right', shadow = True,\n",
    "        facecolor = 'white')\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.savefig(\"/home/aix7101/jeong/CeeBERT/ElasticBERT/Accuracy_vs_layer_Imdb and yelp.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "dqNuO_askX0X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "def softmax(x):\n",
    "    return(np.exp(x)/np.exp(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_thi = []\n",
    "for i in range(len(pred_tuple[0])):\n",
    "    pred_prob_thi.append(max(softmax(pred_tuple[2][i])))\n",
    "# pred_proba_thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uX8DlkDGWdQ-",
    "outputId": "639a3136-cd41-4455-e370-1d02f7e01204"
   },
   "outputs": [],
   "source": [
    "pred_prob_six = []\n",
    "for i in range(len(pred_tuple[0])):\n",
    "    pred_prob_six.append(max(softmax(pred_tuple[5][i])))\n",
    "# pred_proba_fou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.77439725,\n",
       " 0.933595,\n",
       " 0.9837565,\n",
       " 0.95225465,\n",
       " 0.87246877,\n",
       " 0.92590266,\n",
       " 0.98299074,\n",
       " 0.9202023,\n",
       " 0.9199324,\n",
       " 0.7452536,\n",
       " 0.88675195,\n",
       " 0.8895777,\n",
       " 0.8954291,\n",
       " 0.8702636,\n",
       " 0.6825291,\n",
       " 0.96508205,\n",
       " 0.8995163,\n",
       " 0.985123,\n",
       " 0.93711203,\n",
       " 0.97544855,\n",
       " 0.942982,\n",
       " 0.84260285,\n",
       " 0.97623676,\n",
       " 0.9677752,\n",
       " 0.94981396,\n",
       " 0.9832361,\n",
       " 0.94389147,\n",
       " 0.9587094,\n",
       " 0.98186475,\n",
       " 0.80943483,\n",
       " 0.95547974,\n",
       " 0.8840771,\n",
       " 0.9250252,\n",
       " 0.93767303,\n",
       " 0.61386514,\n",
       " 0.9735022,\n",
       " 0.8743685,\n",
       " 0.97818416,\n",
       " 0.8766147,\n",
       " 0.8930864,\n",
       " 0.9176976,\n",
       " 0.9113614,\n",
       " 0.8986581,\n",
       " 0.979465,\n",
       " 0.73662907,\n",
       " 0.98565394,\n",
       " 0.9603537,\n",
       " 0.9239691,\n",
       " 0.9687243,\n",
       " 0.921345,\n",
       " 0.9068655,\n",
       " 0.63428205,\n",
       " 0.94567597,\n",
       " 0.98454154,\n",
       " 0.8784737,\n",
       " 0.5492492,\n",
       " 0.9152902,\n",
       " 0.9789952,\n",
       " 0.91331863,\n",
       " 0.86475044,\n",
       " 0.9837638,\n",
       " 0.89622176,\n",
       " 0.92606664,\n",
       " 0.9368416,\n",
       " 0.9006442,\n",
       " 0.9765103,\n",
       " 0.8336788,\n",
       " 0.9552079,\n",
       " 0.8208733,\n",
       " 0.97510564,\n",
       " 0.888071,\n",
       " 0.94740623,\n",
       " 0.97463346,\n",
       " 0.8680441,\n",
       " 0.90687495,\n",
       " 0.98349625,\n",
       " 0.94185895,\n",
       " 0.64754885,\n",
       " 0.88841903,\n",
       " 0.9782164,\n",
       " 0.9800227,\n",
       " 0.9355689,\n",
       " 0.89800847,\n",
       " 0.98342234,\n",
       " 0.9760452,\n",
       " 0.9218157,\n",
       " 0.55411255,\n",
       " 0.9798671,\n",
       " 0.98397285,\n",
       " 0.9770007,\n",
       " 0.6772785,\n",
       " 0.966032,\n",
       " 0.7915339,\n",
       " 0.9868584,\n",
       " 0.612734,\n",
       " 0.9847481,\n",
       " 0.9235538,\n",
       " 0.54990935,\n",
       " 0.9856956,\n",
       " 0.98139626,\n",
       " 0.92464393,\n",
       " 0.96442133,\n",
       " 0.9808591,\n",
       " 0.8023026,\n",
       " 0.8631615,\n",
       " 0.9802651,\n",
       " 0.57146907,\n",
       " 0.9416896,\n",
       " 0.9711525,\n",
       " 0.8176499,\n",
       " 0.93988127,\n",
       " 0.8456823,\n",
       " 0.98126787,\n",
       " 0.9811679,\n",
       " 0.9328929,\n",
       " 0.7516914,\n",
       " 0.8903993,\n",
       " 0.9320009,\n",
       " 0.9847842,\n",
       " 0.887952,\n",
       " 0.9773391,\n",
       " 0.90066767,\n",
       " 0.931256,\n",
       " 0.83621114,\n",
       " 0.64099973,\n",
       " 0.94594765,\n",
       " 0.98501575,\n",
       " 0.98005646,\n",
       " 0.9766439,\n",
       " 0.9488706,\n",
       " 0.9684029,\n",
       " 0.7705476,\n",
       " 0.9804449,\n",
       " 0.9176662,\n",
       " 0.93212473,\n",
       " 0.6438113,\n",
       " 0.96938306,\n",
       " 0.9568393,\n",
       " 0.9007252,\n",
       " 0.9078496,\n",
       " 0.93783826,\n",
       " 0.97780997,\n",
       " 0.9221125,\n",
       " 0.6833403,\n",
       " 0.70243883,\n",
       " 0.9853827,\n",
       " 0.8058257,\n",
       " 0.9831671,\n",
       " 0.91674864,\n",
       " 0.9624541,\n",
       " 0.9788285,\n",
       " 0.8459106,\n",
       " 0.97553146,\n",
       " 0.9766336,\n",
       " 0.63552785,\n",
       " 0.7739708,\n",
       " 0.98220915,\n",
       " 0.5977785,\n",
       " 0.98479474,\n",
       " 0.8504723,\n",
       " 0.86958736,\n",
       " 0.9532964,\n",
       " 0.90700394,\n",
       " 0.9775893,\n",
       " 0.96683437,\n",
       " 0.8932518,\n",
       " 0.9786019,\n",
       " 0.8863819,\n",
       " 0.537647,\n",
       " 0.8415576,\n",
       " 0.98576015,\n",
       " 0.9809063,\n",
       " 0.938999,\n",
       " 0.72503155,\n",
       " 0.9827786,\n",
       " 0.56225014,\n",
       " 0.9836734,\n",
       " 0.5093512,\n",
       " 0.8984336,\n",
       " 0.96997976,\n",
       " 0.833774,\n",
       " 0.83947235,\n",
       " 0.7146113,\n",
       " 0.9495504,\n",
       " 0.9778815,\n",
       " 0.9767094,\n",
       " 0.5434685,\n",
       " 0.952187,\n",
       " 0.98319197,\n",
       " 0.94592524,\n",
       " 0.8958628,\n",
       " 0.57941896,\n",
       " 0.97955513,\n",
       " 0.752907,\n",
       " 0.88832,\n",
       " 0.92449677,\n",
       " 0.94907093,\n",
       " 0.9806411,\n",
       " 0.91438323,\n",
       " 0.9542719,\n",
       " 0.81601274,\n",
       " 0.96688867,\n",
       " 0.79811525,\n",
       " 0.68268645,\n",
       " 0.93342316,\n",
       " 0.9836363,\n",
       " 0.9649657,\n",
       " 0.7136703,\n",
       " 0.9646458,\n",
       " 0.6884124,\n",
       " 0.7301619,\n",
       " 0.90807,\n",
       " 0.9674303,\n",
       " 0.6165777,\n",
       " 0.75895983,\n",
       " 0.98345804,\n",
       " 0.9722161,\n",
       " 0.942254,\n",
       " 0.9194685,\n",
       " 0.98422575,\n",
       " 0.96304125,\n",
       " 0.890655,\n",
       " 0.8709223,\n",
       " 0.98369384,\n",
       " 0.78480196,\n",
       " 0.982295,\n",
       " 0.93029267,\n",
       " 0.92244124,\n",
       " 0.8182382,\n",
       " 0.93517315,\n",
       " 0.9739077,\n",
       " 0.6751918,\n",
       " 0.9638344,\n",
       " 0.8876103,\n",
       " 0.9832448,\n",
       " 0.9531275,\n",
       " 0.8660608,\n",
       " 0.94764316,\n",
       " 0.94321734,\n",
       " 0.97786003,\n",
       " 0.8369044,\n",
       " 0.93843573,\n",
       " 0.6056984,\n",
       " 0.7898766,\n",
       " 0.843583,\n",
       " 0.97176653,\n",
       " 0.5069562,\n",
       " 0.88840115,\n",
       " 0.8857944,\n",
       " 0.95071995,\n",
       " 0.7278857,\n",
       " 0.8306041,\n",
       " 0.838176,\n",
       " 0.88495046,\n",
       " 0.8440815,\n",
       " 0.9620606,\n",
       " 0.9346243,\n",
       " 0.7129393,\n",
       " 0.64881843,\n",
       " 0.97541386,\n",
       " 0.95404774,\n",
       " 0.9814,\n",
       " 0.9218002,\n",
       " 0.85573643,\n",
       " 0.8277373,\n",
       " 0.9711612,\n",
       " 0.94817317,\n",
       " 0.9802291,\n",
       " 0.9791768,\n",
       " 0.87933046,\n",
       " 0.50390923,\n",
       " 0.7953744,\n",
       " 0.5743868,\n",
       " 0.93596834,\n",
       " 0.8860015,\n",
       " 0.94220376,\n",
       " 0.984099,\n",
       " 0.6781565,\n",
       " 0.9862155,\n",
       " 0.75497264,\n",
       " 0.9836902,\n",
       " 0.94090784,\n",
       " 0.9406683,\n",
       " 0.96280265,\n",
       " 0.9194012,\n",
       " 0.8580927,\n",
       " 0.95355296,\n",
       " 0.55480903,\n",
       " 0.97989,\n",
       " 0.9734569,\n",
       " 0.9388433,\n",
       " 0.95699656,\n",
       " 0.97996587,\n",
       " 0.964314,\n",
       " 0.9820618,\n",
       " 0.980296,\n",
       " 0.973912,\n",
       " 0.9845063,\n",
       " 0.93208736,\n",
       " 0.97408015,\n",
       " 0.9863716,\n",
       " 0.97498363,\n",
       " 0.91318595,\n",
       " 0.98246366,\n",
       " 0.9457505,\n",
       " 0.9654997,\n",
       " 0.9143371,\n",
       " 0.9234688,\n",
       " 0.9800884,\n",
       " 0.8837788,\n",
       " 0.97805166,\n",
       " 0.782014,\n",
       " 0.9788122,\n",
       " 0.9308877,\n",
       " 0.8484358,\n",
       " 0.8517766,\n",
       " 0.9255053,\n",
       " 0.9377036,\n",
       " 0.93452233,\n",
       " 0.9207019,\n",
       " 0.9422247,\n",
       " 0.9811468,\n",
       " 0.9322263,\n",
       " 0.5113497,\n",
       " 0.97224694,\n",
       " 0.9711187,\n",
       " 0.74739987,\n",
       " 0.9306605,\n",
       " 0.9657359,\n",
       " 0.98287904,\n",
       " 0.93994325,\n",
       " 0.90514725,\n",
       " 0.6273842,\n",
       " 0.7398441,\n",
       " 0.9325772,\n",
       " 0.9857131,\n",
       " 0.89533395,\n",
       " 0.89375365,\n",
       " 0.98186475,\n",
       " 0.98164755,\n",
       " 0.7633964,\n",
       " 0.94919664,\n",
       " 0.9742649,\n",
       " 0.88440144,\n",
       " 0.8175812,\n",
       " 0.93785304,\n",
       " 0.94867134,\n",
       " 0.9211157,\n",
       " 0.71584076,\n",
       " 0.7326293,\n",
       " 0.911525,\n",
       " 0.9845337,\n",
       " 0.9468652,\n",
       " 0.97774065,\n",
       " 0.6191041,\n",
       " 0.91114855,\n",
       " 0.9711198,\n",
       " 0.83608925,\n",
       " 0.98591864,\n",
       " 0.9829528,\n",
       " 0.89772815,\n",
       " 0.97372895,\n",
       " 0.85006076,\n",
       " 0.5131127,\n",
       " 0.9533808,\n",
       " 0.97036046,\n",
       " 0.9303232,\n",
       " 0.9787228,\n",
       " 0.7273895,\n",
       " 0.94959927,\n",
       " 0.94334185,\n",
       " 0.9816321,\n",
       " 0.78463715,\n",
       " 0.9872023,\n",
       " 0.98228997,\n",
       " 0.5135758,\n",
       " 0.83472395,\n",
       " 0.8838557,\n",
       " 0.73032755,\n",
       " 0.97199297,\n",
       " 0.9131982,\n",
       " 0.9836762,\n",
       " 0.97958475,\n",
       " 0.9451896,\n",
       " 0.9150824,\n",
       " 0.93311256,\n",
       " 0.9830467,\n",
       " 0.9844559,\n",
       " 0.97870547,\n",
       " 0.8892219,\n",
       " 0.9437761,\n",
       " 0.9791141,\n",
       " 0.9811888,\n",
       " 0.94562185,\n",
       " 0.92046326,\n",
       " 0.92269886,\n",
       " 0.98201585,\n",
       " 0.9789179,\n",
       " 0.6542641,\n",
       " 0.9280904,\n",
       " 0.94324136,\n",
       " 0.89133775,\n",
       " 0.94603103,\n",
       " 0.91061753,\n",
       " 0.9305043,\n",
       " 0.97338974,\n",
       " 0.9846412,\n",
       " 0.9474259,\n",
       " 0.9678321,\n",
       " 0.83253235,\n",
       " 0.9693582,\n",
       " 0.9446511,\n",
       " 0.9828535,\n",
       " 0.97834396,\n",
       " 0.9088664,\n",
       " 0.53105414,\n",
       " 0.9194607,\n",
       " 0.9558678,\n",
       " 0.97528577,\n",
       " 0.9613308,\n",
       " 0.9826566,\n",
       " 0.9792089,\n",
       " 0.8589765,\n",
       " 0.9833612,\n",
       " 0.8599742,\n",
       " 0.91553104,\n",
       " 0.9126245,\n",
       " 0.94562525,\n",
       " 0.98039544,\n",
       " 0.9783061,\n",
       " 0.9735749,\n",
       " 0.7155723,\n",
       " 0.9315892,\n",
       " 0.9515164,\n",
       " 0.8704729,\n",
       " 0.8492629,\n",
       " 0.9223405,\n",
       " 0.87904197,\n",
       " 0.97135746,\n",
       " 0.87353736,\n",
       " 0.9793903,\n",
       " 0.896257,\n",
       " 0.8500243,\n",
       " 0.6275566,\n",
       " 0.91620445,\n",
       " 0.96740186,\n",
       " 0.9648202,\n",
       " 0.9270195,\n",
       " 0.9512606,\n",
       " 0.95486647,\n",
       " 0.9110959,\n",
       " 0.9852178,\n",
       " 0.73358893,\n",
       " 0.8137715,\n",
       " 0.9546379,\n",
       " 0.9844355,\n",
       " 0.60942644,\n",
       " 0.9780719,\n",
       " 0.93771994,\n",
       " 0.72087175,\n",
       " 0.97787887,\n",
       " 0.93639535,\n",
       " 0.93625015,\n",
       " 0.98526615,\n",
       " 0.67225844,\n",
       " 0.9387398,\n",
       " 0.91915995,\n",
       " 0.8450155,\n",
       " 0.8319444,\n",
       " 0.9111508,\n",
       " 0.98624545,\n",
       " 0.9826024,\n",
       " 0.95848143,\n",
       " 0.96436125,\n",
       " 0.9104474,\n",
       " 0.678586,\n",
       " 0.645696,\n",
       " 0.98296046,\n",
       " 0.9434289,\n",
       " 0.96430814,\n",
       " 0.9282898,\n",
       " 0.9771997,\n",
       " 0.6556349,\n",
       " 0.9360996,\n",
       " 0.8866678,\n",
       " 0.90209305,\n",
       " 0.57251376,\n",
       " 0.9726861,\n",
       " 0.97760725,\n",
       " 0.89862007,\n",
       " 0.78102624,\n",
       " 0.9851284,\n",
       " 0.93835354,\n",
       " 0.973434,\n",
       " 0.98329526,\n",
       " 0.97102076,\n",
       " 0.9426249,\n",
       " 0.8896129,\n",
       " 0.9664307,\n",
       " 0.93075746,\n",
       " 0.982735,\n",
       " 0.9458113,\n",
       " 0.56507206,\n",
       " 0.95617676,\n",
       " 0.98506546,\n",
       " 0.94546545,\n",
       " 0.5972629,\n",
       " 0.98432726,\n",
       " 0.9361294,\n",
       " 0.8698074,\n",
       " 0.95267737,\n",
       " 0.98105884,\n",
       " 0.60288185,\n",
       " 0.9218403,\n",
       " 0.9848568,\n",
       " 0.97978956,\n",
       " 0.96291304,\n",
       " 0.92498434,\n",
       " 0.8014134,\n",
       " 0.9604785,\n",
       " 0.8973752,\n",
       " 0.9293278,\n",
       " 0.919488,\n",
       " 0.98361486,\n",
       " 0.7493894,\n",
       " 0.98328334,\n",
       " 0.80740553,\n",
       " 0.97448146,\n",
       " 0.97787106,\n",
       " 0.84705275,\n",
       " 0.9844433,\n",
       " 0.9005108,\n",
       " 0.9829392,\n",
       " 0.9784919,\n",
       " 0.92587936,\n",
       " 0.963751,\n",
       " 0.6479308,\n",
       " 0.6155676,\n",
       " 0.85783184,\n",
       " 0.9847105,\n",
       " 0.9500536,\n",
       " 0.95767796,\n",
       " 0.97947013,\n",
       " 0.9143569,\n",
       " 0.9654078,\n",
       " 0.9442828,\n",
       " 0.8750834,\n",
       " 0.9702992,\n",
       " 0.952437,\n",
       " 0.9370085,\n",
       " 0.9017757,\n",
       " 0.97777563,\n",
       " 0.9438833,\n",
       " 0.91075134,\n",
       " 0.8650878,\n",
       " 0.9543962,\n",
       " 0.9187839,\n",
       " 0.97762674,\n",
       " 0.9313029,\n",
       " 0.91519475,\n",
       " 0.9753355,\n",
       " 0.91585404,\n",
       " 0.60881466,\n",
       " 0.91578805,\n",
       " 0.7319149,\n",
       " 0.9756375,\n",
       " 0.98100215,\n",
       " 0.66305226,\n",
       " 0.9647976,\n",
       " 0.9803594,\n",
       " 0.82691735,\n",
       " 0.8929232,\n",
       " 0.9850076,\n",
       " 0.98524123,\n",
       " 0.98114043,\n",
       " 0.8913115,\n",
       " 0.93961644,\n",
       " 0.9832553,\n",
       " 0.63864857,\n",
       " 0.82074606,\n",
       " 0.98099744,\n",
       " 0.89912814,\n",
       " 0.97825205,\n",
       " 0.770314,\n",
       " 0.97842956,\n",
       " 0.98013884,\n",
       " 0.9202256,\n",
       " 0.8767261,\n",
       " 0.58863163,\n",
       " 0.9439874,\n",
       " 0.78005,\n",
       " 0.920211,\n",
       " 0.8363189,\n",
       " 0.88964,\n",
       " 0.5700345,\n",
       " 0.9386811,\n",
       " 0.97471124,\n",
       " 0.98281354,\n",
       " 0.55467564,\n",
       " 0.9279726,\n",
       " 0.9550614,\n",
       " 0.9046096,\n",
       " 0.88226104,\n",
       " 0.9828364,\n",
       " 0.9353644,\n",
       " 0.98208606,\n",
       " 0.5374981,\n",
       " 0.84323686,\n",
       " 0.9818428,\n",
       " 0.9397448,\n",
       " 0.9691271,\n",
       " 0.6485224,\n",
       " 0.98320776,\n",
       " 0.96631074,\n",
       " 0.9326841,\n",
       " 0.7792806,\n",
       " 0.9526224,\n",
       " 0.5973711,\n",
       " 0.97711545,\n",
       " 0.97106135,\n",
       " 0.9494322,\n",
       " 0.97780436,\n",
       " 0.91858983,\n",
       " 0.95398206,\n",
       " 0.98125076,\n",
       " 0.9735491,\n",
       " 0.98355675,\n",
       " 0.97538745,\n",
       " 0.9486339,\n",
       " 0.9672018,\n",
       " 0.9709436,\n",
       " 0.98431754,\n",
       " 0.9154152,\n",
       " 0.9250496,\n",
       " 0.9755656,\n",
       " 0.81858814,\n",
       " 0.93682873,\n",
       " 0.9157518,\n",
       " 0.7835821,\n",
       " 0.98158467,\n",
       " 0.9359338,\n",
       " 0.8817981,\n",
       " 0.88818765,\n",
       " 0.8932379,\n",
       " 0.97951597,\n",
       " 0.80621856,\n",
       " 0.5604117,\n",
       " 0.93749243,\n",
       " 0.90632725,\n",
       " 0.76778364,\n",
       " 0.9258799,\n",
       " 0.916232,\n",
       " 0.97584665,\n",
       " 0.58348894,\n",
       " 0.8879074,\n",
       " 0.9573266,\n",
       " 0.97543114,\n",
       " 0.8930201,\n",
       " 0.91885334,\n",
       " 0.9852774,\n",
       " 0.76673627,\n",
       " 0.9455008,\n",
       " 0.9447081,\n",
       " 0.9865932,\n",
       " 0.9815295,\n",
       " 0.957939,\n",
       " 0.93010306,\n",
       " 0.50122434,\n",
       " 0.81065965,\n",
       " 0.551454,\n",
       " 0.97980154,\n",
       " 0.9828742,\n",
       " 0.9782386,\n",
       " 0.9782674,\n",
       " 0.61738205,\n",
       " 0.94332546,\n",
       " 0.97552365,\n",
       " 0.97933257,\n",
       " 0.7065244,\n",
       " 0.79939073,\n",
       " 0.9677034,\n",
       " 0.5048555,\n",
       " 0.86253166,\n",
       " 0.9812593,\n",
       " 0.9744832,\n",
       " 0.6135308,\n",
       " 0.6412796,\n",
       " 0.61660045,\n",
       " 0.7167903,\n",
       " 0.6256955,\n",
       " 0.92939174,\n",
       " 0.75516367,\n",
       " 0.95869696,\n",
       " 0.9770961,\n",
       " 0.9496363,\n",
       " 0.98404604,\n",
       " 0.88729995,\n",
       " 0.97461677,\n",
       " 0.9740428,\n",
       " 0.9134674,\n",
       " 0.9250026,\n",
       " 0.9818321,\n",
       " 0.95192385,\n",
       " 0.9587928,\n",
       " 0.97496563,\n",
       " 0.9000089,\n",
       " 0.957084,\n",
       " 0.9843431,\n",
       " 0.91252035,\n",
       " 0.98522794,\n",
       " 0.9769289,\n",
       " 0.9205097,\n",
       " 0.87026894,\n",
       " 0.87594914,\n",
       " 0.98491275,\n",
       " 0.9723926,\n",
       " 0.7669635,\n",
       " 0.9793321,\n",
       " 0.93459934,\n",
       " 0.9851832,\n",
       " 0.92214143,\n",
       " 0.98053056,\n",
       " 0.93642396,\n",
       " 0.88135564,\n",
       " 0.92058736,\n",
       " 0.95163816,\n",
       " 0.969117,\n",
       " 0.95097744,\n",
       " 0.8596083,\n",
       " 0.97643393,\n",
       " 0.9786741,\n",
       " 0.9153155,\n",
       " 0.94604254,\n",
       " 0.94134647,\n",
       " 0.96473026,\n",
       " 0.82356167,\n",
       " 0.9733839,\n",
       " 0.9858931,\n",
       " 0.7962627,\n",
       " 0.9688524,\n",
       " 0.9320863,\n",
       " 0.7660153,\n",
       " 0.9834631,\n",
       " 0.94945365,\n",
       " 0.98052573,\n",
       " 0.8800283,\n",
       " 0.9318283,\n",
       " 0.9746794,\n",
       " 0.971672,\n",
       " 0.9293076,\n",
       " 0.8615599,\n",
       " 0.7205028,\n",
       " 0.9796293,\n",
       " 0.8983622,\n",
       " 0.93518436,\n",
       " 0.88205224,\n",
       " 0.9444462,\n",
       " 0.94023246,\n",
       " 0.94811606,\n",
       " 0.93116283,\n",
       " 0.98264134,\n",
       " 0.64393294,\n",
       " 0.82253,\n",
       " 0.96570486,\n",
       " 0.9495684,\n",
       " 0.84770644,\n",
       " 0.98241574,\n",
       " 0.93189293,\n",
       " 0.9806282,\n",
       " 0.9729571,\n",
       " 0.53749216,\n",
       " 0.91817874,\n",
       " 0.8659145,\n",
       " 0.97418106,\n",
       " 0.9575288,\n",
       " 0.9514278,\n",
       " 0.98180205,\n",
       " 0.5337575,\n",
       " 0.9718047,\n",
       " 0.82490784,\n",
       " 0.9626949,\n",
       " 0.97792315,\n",
       " 0.97938955,\n",
       " 0.97602683,\n",
       " 0.91890144,\n",
       " 0.9292141,\n",
       " 0.91385514,\n",
       " 0.8807265,\n",
       " 0.971256,\n",
       " 0.97393197,\n",
       " 0.9086709,\n",
       " 0.5009519,\n",
       " 0.8124134,\n",
       " 0.91945827,\n",
       " 0.98113406,\n",
       " 0.9804097,\n",
       " 0.9137149,\n",
       " 0.98401546,\n",
       " 0.9282823,\n",
       " 0.9838675,\n",
       " 0.98212856,\n",
       " 0.860715,\n",
       " 0.9530985,\n",
       " 0.93811446,\n",
       " 0.9804684,\n",
       " 0.98121274,\n",
       " 0.86365193,\n",
       " 0.94311213,\n",
       " 0.9715945,\n",
       " 0.93722457,\n",
       " 0.98517257,\n",
       " 0.65910494,\n",
       " 0.9832699,\n",
       " 0.9810157,\n",
       " 0.85748255,\n",
       " 0.8556399,\n",
       " 0.93267995,\n",
       " 0.9829875,\n",
       " 0.98122805,\n",
       " 0.8981463,\n",
       " 0.95771176,\n",
       " 0.9750094,\n",
       " 0.9496382,\n",
       " 0.9788051,\n",
       " 0.97165596,\n",
       " 0.9421919,\n",
       " 0.91461295,\n",
       " 0.9816132,\n",
       " 0.97277635,\n",
       " 0.98206514,\n",
       " 0.89963037,\n",
       " 0.81762445,\n",
       " 0.94132364,\n",
       " 0.9776416,\n",
       " 0.9860615,\n",
       " 0.9826354,\n",
       " 0.9823405,\n",
       " 0.5644433,\n",
       " 0.9608359,\n",
       " 0.9845665,\n",
       " 0.940696,\n",
       " 0.9776497,\n",
       " 0.90624696,\n",
       " 0.933873,\n",
       " 0.98221385,\n",
       " 0.8711212,\n",
       " 0.97631794,\n",
       " 0.764284,\n",
       " 0.7469364,\n",
       " 0.81404036,\n",
       " 0.92051786,\n",
       " 0.580355,\n",
       " 0.98261595,\n",
       " 0.9749575,\n",
       " 0.9858035,\n",
       " 0.9177737,\n",
       " 0.86294574,\n",
       " 0.9801973,\n",
       " 0.9803923,\n",
       " 0.71514684,\n",
       " 0.9804105,\n",
       " 0.7974244,\n",
       " 0.92579097,\n",
       " 0.87358725,\n",
       " 0.9796144,\n",
       " 0.76411754,\n",
       " 0.9859659,\n",
       " 0.96846485,\n",
       " 0.6559717,\n",
       " 0.9215243,\n",
       " 0.8958047,\n",
       " 0.5216624,\n",
       " 0.5673068,\n",
       " 0.6655203,\n",
       " 0.91242415,\n",
       " 0.9316411,\n",
       " 0.9818379,\n",
       " 0.9849872,\n",
       " 0.9018043,\n",
       " 0.7121956,\n",
       " 0.9494148,\n",
       " 0.98016495,\n",
       " 0.534989,\n",
       " 0.9752677,\n",
       " 0.9292522,\n",
       " 0.9794102,\n",
       " 0.82544523,\n",
       " 0.93731165,\n",
       " 0.95709413,\n",
       " 0.82802594,\n",
       " 0.9731197,\n",
       " 0.9175291,\n",
       " 0.89920473,\n",
       " 0.95150626,\n",
       " 0.9745103,\n",
       " 0.98574674,\n",
       " 0.98405665,\n",
       " 0.9840666,\n",
       " 0.5286023,\n",
       " 0.9836935,\n",
       " 0.9714948,\n",
       " 0.94619936,\n",
       " 0.9687368,\n",
       " 0.86520845,\n",
       " 0.9783263,\n",
       " 0.88438404,\n",
       " 0.98364544,\n",
       " 0.98280513,\n",
       " 0.8473807,\n",
       " 0.9837924,\n",
       " 0.92329526,\n",
       " 0.88749695,\n",
       " 0.9121955,\n",
       " 0.6354488,\n",
       " 0.9837458,\n",
       " 0.94026846,\n",
       " 0.82206947,\n",
       " 0.82118255,\n",
       " 0.7649583,\n",
       " 0.66716343,\n",
       " 0.79848814,\n",
       " 0.8785826,\n",
       " 0.9305647,\n",
       " 0.9038668,\n",
       " 0.94710994,\n",
       " 0.9729229,\n",
       " 0.94900435,\n",
       " 0.98443556,\n",
       " 0.98275167,\n",
       " 0.9780967,\n",
       " 0.715093,\n",
       " 0.9521514,\n",
       " 0.9068549,\n",
       " 0.6316234,\n",
       " 0.8212991,\n",
       " 0.926026,\n",
       " 0.96364784,\n",
       " 0.67796224,\n",
       " 0.9323516,\n",
       " 0.94578224,\n",
       " 0.9353508,\n",
       " 0.9404228,\n",
       " 0.9761403,\n",
       " 0.964941,\n",
       " 0.81420714,\n",
       " 0.94553494,\n",
       " 0.9666841,\n",
       " 0.97372353,\n",
       " 0.6265692,\n",
       " 0.98100126,\n",
       " 0.90597403,\n",
       " 0.9443227,\n",
       " 0.9573349,\n",
       " 0.9844434,\n",
       " 0.9804982,\n",
       " 0.98212403,\n",
       " 0.93046314,\n",
       " 0.9437134,\n",
       " 0.9647534,\n",
       " 0.9828665,\n",
       " 0.90930396,\n",
       " 0.985739,\n",
       " 0.92748314,\n",
       " 0.93324476,\n",
       " 0.8844452,\n",
       " 0.9444283,\n",
       " 0.9506021,\n",
       " 0.8740871,\n",
       " 0.98461777,\n",
       " 0.88885313,\n",
       " 0.8418265,\n",
       " 0.90487516,\n",
       " 0.9232216,\n",
       " 0.98254496,\n",
       " 0.97534,\n",
       " 0.87843513,\n",
       " 0.95041496,\n",
       " 0.9813937,\n",
       " 0.98094666,\n",
       " 0.9824717,\n",
       " 0.97691065,\n",
       " 0.7407947,\n",
       " 0.9772107,\n",
       " 0.9832208,\n",
       " 0.9442717,\n",
       " 0.9738798,\n",
       " 0.72754705,\n",
       " 0.9093784,\n",
       " 0.9826116,\n",
       " 0.8996545,\n",
       " 0.9389932,\n",
       " 0.7328363,\n",
       " 0.9799451,\n",
       " 0.9828839,\n",
       " 0.9836784,\n",
       " 0.77254957,\n",
       " 0.9290001,\n",
       " 0.94063646,\n",
       " 0.9496045,\n",
       " 0.9841469,\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_las = []\n",
    "for i in range(len(pred_tuple[0])):\n",
    "    pred_prob_las.append(max(softmax(pred_tuple[-1][i])))\n",
    "pred_prob_las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67349"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859232"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(pred_prob_thi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_labels_1 = []\n",
    "for i in op_labels:\n",
    "    if i == 0:\n",
    "        op_labels_1.append(1)\n",
    "    elif i==1:\n",
    "        op_labels_1.append(2)\n",
    "    else:\n",
    "        op_labels_1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gGJUAlUIH3SP"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(final_preds[2],final_preds[5], final_preds[-1], pred_prob_thi, pred_prob_six, pred_prob_las, op_labels_1)), columns =['Thi_layer_P','Six_layer_P', 'Last_layer','PProb_thi', 'PProb_six', 'PProb_las', 'True_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67349\n"
     ]
    }
   ],
   "source": [
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "H8RVPJMeXU9E"
   },
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame(list(zip(final_preds[0], final_preds[1], final_preds[2], final_preds[3], final_preds[4], final_preds[5], final_preds[6], final_preds[7], final_preds[8], final_preds[9], final_preds[10], final_preds[11], op_labels)), columns =['Fir_p', 'Sec_p', 'Thi_p', 'Fou_p', 'Fiv_p', 'Six_p', 'Sev_p', 'Eig_p', 'Nin_p', 'Ten_p', 'Ele_p', 'Twe_p', 'True_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "SJdbOqbi2AiL"
   },
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(list(zip(final_preds[0], final_preds[1], final_preds[2], final_preds[3], final_preds[4], final_preds[5], final_preds[6], op_labels)), columns =['Fir_p', 'Thi_p', 'Fou_p', 'Fiv_p', 'Sev_p', 'Nin_p', 'Twe_p', 'True_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "eePvXaR2g44c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thi_layer_P</th>\n",
       "      <th>Six_layer_P</th>\n",
       "      <th>Last_layer</th>\n",
       "      <th>PProb_thi</th>\n",
       "      <th>PProb_six</th>\n",
       "      <th>PProb_las</th>\n",
       "      <th>True_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501985</td>\n",
       "      <td>0.792879</td>\n",
       "      <td>0.774397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536737</td>\n",
       "      <td>0.931072</td>\n",
       "      <td>0.933595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644276</td>\n",
       "      <td>0.972236</td>\n",
       "      <td>0.983756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607871</td>\n",
       "      <td>0.939443</td>\n",
       "      <td>0.952255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521170</td>\n",
       "      <td>0.879392</td>\n",
       "      <td>0.872469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Thi_layer_P  Six_layer_P  Last_layer  PProb_thi  PProb_six  PProb_las  \\\n",
       "0            1            0           0   0.501985   0.792879   0.774397   \n",
       "1            1            0           0   0.536737   0.931072   0.933595   \n",
       "2            1            1           1   0.644276   0.972236   0.983756   \n",
       "3            1            1           1   0.607871   0.939443   0.952255   \n",
       "4            0            0           0   0.521170   0.879392   0.872469   \n",
       "\n",
       "   True_labels  \n",
       "0            1  \n",
       "1            1  \n",
       "2            2  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gfj1nbWqfea4",
    "outputId": "967cc785-e147-4b62-a3e5-29c02a8df442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.35243284978247635\n",
      "Accuracy =  0.07309685370235638\n",
      "Accuracy =  0.060594812098175174\n",
      "Accuracy =  0.0\n",
      "Accuracy =  0.0\n",
      "Accuracy =  0.0\n",
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_imdb = []\n",
    "for j in df.columns:\n",
    "  accuracy = 0\n",
    "  for i in range(df.shape[0]):\n",
    "      if df[j][i] == df['True_labels'][i]:\n",
    "          accuracy += 1\n",
    "      else:\n",
    "          pass\n",
    "  print(\"Accuracy = \", accuracy/df.shape[0])\n",
    "  accuracy_imdb.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "piV1ZUbg1zhc",
    "outputId": "70c2daee-416d-4598-8ff0-8aaf349d899f"
   },
   "outputs": [],
   "source": [
    "# accuracy_yelp = []\n",
    "# for j in df2.columns:\n",
    "#   accuracy = 0\n",
    "#   for i in range(df1.shape[0]):\n",
    "#       if df2[j][i] == df2['True_labels'][i]:\n",
    "#           accuracy += 1\n",
    "#       else:\n",
    "#           pass\n",
    "#   print(\"Accuracy = \", accuracy/df2.shape[0])\n",
    "#   accuracy_imdb.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "mgX5cPgt8vZr"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/aix7101/jeong/CeeBERT/ElasticBERT/Early_Exit_Confidence_data_snli_max_exits(3,6,12)_difference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "dE2200MMhJz1"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(r\"/UBERT/CSV_files/Early_Exit_Confidence_data_SST2_new_exits(12,12)_difference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOpSU7ShmMU6",
    "outputId": "34d6d257-a43b-4d4f-d2d3-9396cf5fa963"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aix7101/jeong/CeeBERT/ElasticBERT/finetune-dynamic/load_data.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(cached_features_file)\n",
      "Evaluating: 100%|██████████| 2105/2105 [01:21<00:00, 25.94it/s]\n",
      "Evaluating: 100%|██████████| 2105/2105 [01:22<00:00, 25.40it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m get_preds(eval_dataset\u001b[38;5;241m=\u001b[39mdataset, data_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df_test \u001b[38;5;241m=\u001b[39m get_preds(eval_dataset\u001b[38;5;241m=\u001b[39mdataset, data_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_tot \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_tot \u001b[38;5;241m=\u001b[39m df_tot\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_tot\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/pandas/core/reshape/concat.py:448\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/pandas/core/reshape/concat.py:489\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    485\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m         )\n\u001b[0;32m--> 489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    491\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "df_train = get_preds(eval_dataset=dataset, data_split='train')\n",
    "df_test = get_preds(eval_dataset=dataset, data_split='test')\n",
    "\n",
    "df_tot = pd.concat([df_train, df_test])\n",
    "df_tot = df_tot.reset_index(drop=True)\n",
    "print(df_tot.head())\n",
    "\n",
    "df_tot.to_csv(r'/home/aix7101/jeong/CeeBERT/Early_Exits_Divya/Model_exit_predictions/Exit_Predictions_TrainTest_IMDb_8exits.csv',sep ='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlgCgxMQm17O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "j_ceebert",
   "language": "python",
   "name": "j_ceebert"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
