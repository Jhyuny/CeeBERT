{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Tu4XH1qvIu1m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LPVyU-8-xOuI",
    "outputId": "18f44abc-28b3-4464-ccbf-a1ecdad308aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Thi_layer_P</th>\n",
       "      <th>Fou_layer_P</th>\n",
       "      <th>Last_layer</th>\n",
       "      <th>PProb_thi</th>\n",
       "      <th>PProb_fou</th>\n",
       "      <th>PProb_las</th>\n",
       "      <th>True_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753920</td>\n",
       "      <td>0.800089</td>\n",
       "      <td>0.845397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594112</td>\n",
       "      <td>0.815985</td>\n",
       "      <td>0.813593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.822457</td>\n",
       "      <td>0.724403</td>\n",
       "      <td>0.820971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743167</td>\n",
       "      <td>0.728612</td>\n",
       "      <td>0.674946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638572</td>\n",
       "      <td>0.865548</td>\n",
       "      <td>0.837171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Thi_layer_P  Fou_layer_P  Last_layer  PProb_thi  PProb_fou  \\\n",
       "0           0            0            0           0   0.753920   0.800089   \n",
       "1           1            0            1           1   0.594112   0.815985   \n",
       "2           2            0            0           0   0.822457   0.724403   \n",
       "3           3            0            0           0   0.743167   0.728612   \n",
       "4           4            1            1           1   0.638572   0.865548   \n",
       "\n",
       "   PProb_las  True_labels  \n",
       "0   0.845397            0  \n",
       "1   0.813593            1  \n",
       "2   0.820971            0  \n",
       "3   0.674946            0  \n",
       "4   0.837171            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/aix7101/jeong/CeeBERT/Early_Exit_Confidence_data_yelp_max_exits(3,4,12)_difference.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set_1 = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # threshold candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_imdb = []\n",
    "# for j in df.columns:\n",
    "#   accuracy = 0\n",
    "#   for i in range(df.shape[0]):\n",
    "#       if df[j][i] == df['True_labels'][i]:\n",
    "#           accuracy += 1\n",
    "#       else:\n",
    "#           pass\n",
    "#   print(\"Accuracy = \", accuracy/df.shape[0])\n",
    "#   accuracy_imdb.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.6]\n"
     ]
    }
   ],
   "source": [
    "print([action_set_1[0], action_set_1[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set = []\n",
    "act_mat = np.zeros([len(action_set_1), len(action_set_1), 2])\n",
    "for i in range(act_mat.shape[0]):\n",
    "    for j in range(act_mat.shape[1]):\n",
    "        # if i>j:     \n",
    "        act_mat[i][j] = np.array([action_set_1[i], action_set_1[j]])\n",
    "        action_set.append(act_mat[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_set) # 2개의 threshold 후보를 택해서 사용, 6개의 후보 중 총 36개의 후보를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.5, 0.5]), array([0.5, 0.6]), array([0.5, 0.7]), array([0.5, 0.8]), array([0.5, 0.9]), array([0.5, 1. ]), array([0.6, 0.5]), array([0.6, 0.6]), array([0.6, 0.7]), array([0.6, 0.8]), array([0.6, 0.9]), array([0.6, 1. ]), array([0.7, 0.5]), array([0.7, 0.6]), array([0.7, 0.7]), array([0.7, 0.8]), array([0.7, 0.9]), array([0.7, 1. ]), array([0.8, 0.5]), array([0.8, 0.6]), array([0.8, 0.7]), array([0.8, 0.8]), array([0.8, 0.9]), array([0.8, 1. ]), array([0.9, 0.5]), array([0.9, 0.6]), array([0.9, 0.7]), array([0.9, 0.8]), array([0.9, 0.9]), array([0.9, 1. ]), array([1. , 0.5]), array([1. , 0.6]), array([1. , 0.7]), array([1. , 0.8]), array([1. , 0.9]), array([1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "print((action_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One_UBERT_Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_cycle(df, action_set, overhead):\n",
    "    c_i_data_thi = []\n",
    "    for i in df[\"PProb_thi\"]:\n",
    "        c_i_data_thi.append(i)\n",
    "\n",
    "    c_i_data_six = []\n",
    "    for i in df[\"PProb_six\"]:\n",
    "        c_i_data_six.append(i)\n",
    "\n",
    "    c_l_data = []\n",
    "    for i in df[\"PProb_las\"]:\n",
    "        c_l_data.append(i)\n",
    "        \n",
    "    # action_set_1 = [0.10*((i+10)/3) for i in range(20)]\n",
    "    # action_set = []\n",
    "    # for i in range(len(action_set_1)):\n",
    "    #     if i%2 == 0:\n",
    "    #         action_set.append(action_set_1[i])\n",
    "    \n",
    "    \n",
    "    def reward(c_i_thi, c_i_six, c_l, action, overhead):\n",
    "        if c_i_thi >= action_set[action][0]:\n",
    "            reward = 0\n",
    "        elif c_i_six >= action_set[action][1]:\n",
    "            reward = c_i_six - c_i_thi - overhead[0] \n",
    "        else:\n",
    "            reward = c_l - c_i_thi - overhead[0] - overhead[1]\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def next_action(Q, c_tilde, N, t):\n",
    "      # Q is the list of rewards\n",
    "      # c_tilde is the hyperparameter\n",
    "      # N is the number of times an action is chosen\n",
    "        next_a = []\n",
    "        for i in range(len(action_set)):\n",
    "\n",
    "            next_a.append(Q[i] + c_tilde*((np.log(t)/N[i])**(0.5)))\n",
    "\n",
    "        return next_a.index(max(next_a))\n",
    "    \n",
    "    \n",
    "    def update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, chosen_action, overhead):\n",
    "        n = N[chosen_action]\n",
    "        N[chosen_action] += 1\n",
    "        Q[chosen_action] = (n*Q[chosen_action] + reward(c_i_data_thi[t], c_i_data_six[t], c_l_data[t], chosen_action, overhead))/N[chosen_action]\n",
    "        return Q, N\n",
    "    \n",
    "    \n",
    "\n",
    "    def initialize(Q, N, action_set, c_i_data_thi, c_i_data_six, c_l_data, overhead):\n",
    "        for t in range(len(action_set)):\n",
    "            update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, t, overhead)\n",
    "        # print(N)\n",
    "        return Q, N\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def oracle_action(overhead):\n",
    "        oracle_reward = []\n",
    "        for i in action_set:\n",
    "            o_reward = 0 \n",
    "            for t in range(df.shape[0]):\n",
    "                if c_i_data_thi[t] >= i[0]:\n",
    "                    reward = 0\n",
    "    #                 predictions.append(df[\"Fou_layer_P\"][t])\n",
    "                elif c_i_data_six[t] >= i[1]:\n",
    "                    reward = c_i_data_six[t] - c_i_data_thi[t] - overhead[0] \n",
    "                else:\n",
    "                    reward = c_l_data[t] - c_i_data_thi[t] - overhead[0] - overhead[1] \n",
    "                o_reward += reward\n",
    "    #         print(oracle_reward)\n",
    "            oracle_reward.append(o_reward/df.shape[0])\n",
    "\n",
    "        return oracle_reward.index(max(oracle_reward)), oracle_reward\n",
    "    oracle_action, o_reward = oracle_action(overhead)\n",
    "    \n",
    "    \n",
    "    print(\"Oracle action =====> \", oracle_action)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def one_UCB_cycle(Q, N, c_tilde, c_i_data_thi, c_i_data_six, c_l_data, overhead, df):\n",
    "        action_chosen = []\n",
    "        predictions = []\n",
    "        rewards = []\n",
    "        count_1 = 0\n",
    "        count_2 = 0\n",
    "        for t in range(df.shape[0]):\n",
    "            if t < len(action_set):\n",
    "                action = action_set[t]\n",
    "                action_chosen.append(action)\n",
    "                if c_i_data_thi[t] >= action_set[t][0]:\n",
    "                    reward = 0\n",
    "                    predictions.append(df[\"Thi_layer_P\"][t])\n",
    "                    rewards.append(reward)\n",
    "                elif c_i_data_six[t] >= action_set[t][1]:\n",
    "                    reward = c_i_data_six[t] - c_i_data_thi[t] - overhead[0]\n",
    "                    predictions.append(df[\"Six_layer_P\"][t])\n",
    "                    rewards.append(reward)\n",
    "                else:\n",
    "                    reward = c_l_data[t] - c_i_data_thi[t] - overhead[0] - overhead[1]\n",
    "                    predictions.append(df[\"Last_layer\"][t])\n",
    "                    rewards.append(reward)\n",
    "\n",
    "            else:\n",
    "\n",
    "                action = next_action(Q, c_tilde, N, t)\n",
    "                # print(action)\n",
    "                action_chosen.append(action)\n",
    "                if c_i_data_thi[t] >= action_set[action][0]:\n",
    "                    reward = 0\n",
    "                    predictions.append(df[\"Thi_layer_P\"][t])\n",
    "                    rewards.append(reward)\n",
    "                    count_1+=1\n",
    "                    for i in range(len(action_set)):\n",
    "                        if action_set[i][0] == action_set[action][0] and action_set[i][1] != action_set[action][1]:\n",
    "                            Q, N = update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, i, overhead)\n",
    "                        elif action_set[i][0] < action_set[action][0]:\n",
    "                            Q, N = update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, i, overhead)\n",
    "                        else:\n",
    "                            pass\n",
    "                elif c_i_data_six[t] >= action_set[action][1]:\n",
    "                    reward = c_i_data_six[t] - c_i_data_thi[t] - overhead[0]\n",
    "                    predictions.append(df[\"Six_layer_P\"][t])\n",
    "                    rewards.append(reward)\n",
    "                    count_2+=1  \n",
    "                    # Q, N = update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, action, overhead)\n",
    "                    for i in range(len(action_set)):\n",
    "                        if action_set[i][0] > action_set[action][0] and action_set[i][1] < action_set[action][1]:\n",
    "                            Q, N = update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, i, overhead)\n",
    "                        else:\n",
    "                            pass\n",
    "                else:\n",
    "                    reward = c_l_data[t] - c_i_data_thi[t] - overhead[0] - overhead[1]\n",
    "                    predictions.append(df[\"Last_layer\"][t])\n",
    "                    rewards.append(reward)\n",
    "                    for i in range(len(action_set)):\n",
    "                        if action_set[i][0] > action_set[action][0] and action_set[i][1] > action_set[action][1]:\n",
    "                            Q, N = update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, i, overhead)\n",
    "                        else:\n",
    "                            pass\n",
    "                    \n",
    "                    # Q, N = update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, action, overhead)\n",
    "                Q, N = update_parameters(Q, N, t, c_i_data_thi, c_i_data_six, c_l_data, action, overhead)\n",
    "                \n",
    "\n",
    "        return action_chosen, predictions, rewards, Q, N, count_1, count_2\n",
    "    \n",
    "    \n",
    "    Q = [0 for i in range(len(action_set))]\n",
    "    N = [0 for i in range(len(action_set))]\n",
    "    c_tilde = 2\n",
    "    Q, N = initialize(Q, N, action_set, c_i_data_thi,c_i_data_six, c_l_data, overhead)\n",
    "    action, preds, rewards, Q, N, count_1, count_2 = one_UCB_cycle(Q, N, c_tilde, c_i_data_thi, c_i_data_six, c_l_data, overhead , df)\n",
    "    \n",
    "    optimal_action = Q.index(max(Q))\n",
    "    print(\"Optimal_action is \", optimal_action)\n",
    "\n",
    "    \n",
    "    \n",
    "    preds = []\n",
    "    count = 0\n",
    "    oracle_reward = []\n",
    "    for i in range(df.shape[0]):\n",
    "        \n",
    "        if c_i_data_thi[i] > action_set[oracle_action][0]:\n",
    "            reward = 0\n",
    "            count += 1\n",
    "            preds.append(df[\"Thi_layer_P\"][i])\n",
    "            oracle_reward.append(reward)\n",
    "        elif c_i_data_six[i] > action_set[oracle_action][1]:\n",
    "            reward = c_i_data_six[i] - c_i_data_thi[i] - overhead[0]\n",
    "            count += 1\n",
    "            preds.append(df[\"Six_layer_P\"][i])\n",
    "            oracle_reward.append(reward)\n",
    "        else:\n",
    "            preds.append(df[\"Last_layer\"][i])\n",
    "            reward = c_l_data[i] - c_i_data_thi[i] - overhead[0] - overhead[1]\n",
    "            oracle_reward.append(reward)\n",
    "                \n",
    "    oracle_reward = np.array(oracle_reward)\n",
    "    rewards = np.array(rewards)\n",
    "    regret = (oracle_reward-rewards)\n",
    "    cumulative_regret = abs(np.cumsum(regret))\n",
    "    \n",
    "    \n",
    "    return cumulative_regret, count_1, count_2, action_set[optimal_action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cycle(df, action_set, overhead = [0.1, 0.06])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i in range(df.shape[0]):\n",
    "    if i%50 == 0:\n",
    "        idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PProb_six'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PProb_six'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_cycles):\n\u001b[1;32m      7\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(frac \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     cum_reg,_,_,_ \u001b[38;5;241m=\u001b[39m \u001b[43mone_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverhead\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.06\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.04\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     reg_lis\u001b[38;5;241m.\u001b[39mappend([cum_reg[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m idx])\n\u001b[1;32m     13\u001b[0m reg_lis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(reg_lis)\n",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m, in \u001b[0;36mone_cycle\u001b[0;34m(df, action_set, overhead)\u001b[0m\n\u001b[1;32m      4\u001b[0m     c_i_data_thi\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m      6\u001b[0m c_i_data_six \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPProb_six\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      8\u001b[0m     c_i_data_six\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     10\u001b[0m c_l_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/j_ceebert/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PProb_six'"
     ]
    }
   ],
   "source": [
    "num_cycles = 5\n",
    "reg_lis = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    df = df.sample(frac = 1)\n",
    "    cum_reg,_,_,_ = one_cycle(df, action_set, overhead = [0.06, 0.04])\n",
    "\n",
    "\n",
    "    reg_lis.append([cum_reg[j] for j in idx])\n",
    "    \n",
    "reg_lis = np.array(reg_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reg_lis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = []\n",
    "upper = []\n",
    "\n",
    "for i in range(len(reg_lis[0])):\n",
    "\n",
    "    intrval = st.t.interval(alpha=0.95, df=len(reg_lis[:,i])-1,\n",
    "            loc=np.mean(reg_lis[:,i]),\n",
    "            scale=st.sem(reg_lis[:,i]))\n",
    "        \n",
    "    lower.append(intrval[0])\n",
    "    upper.append(intrval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other-Exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_action_cycle(df, action_set, action, overhead):\n",
    "    c_i_data_thi = []\n",
    "    for i in df[\"PProb_thi\"]:\n",
    "        c_i_data_thi.append(i)\n",
    "\n",
    "    c_i_data_six = []\n",
    "    for i in df[\"PProb_six\"]:\n",
    "        c_i_data_six.append(i)\n",
    "\n",
    "    c_l_data = []\n",
    "    for i in df[\"PProb_las\"]:\n",
    "        c_l_data.append(i)\n",
    "\n",
    "    # number_of_actions = 10\n",
    "    # action_set = [0.10*((i+10)/2) for i in range(number_of_actions)]\n",
    "        \n",
    "    # action_set_1 = [0.10*((i+10)/3) for i in range(20)]\n",
    "    # action_set = []\n",
    "    # for i in range(len(action_set_1)):\n",
    "    #     if i%2 == 0:\n",
    "    #         action_set.append(action_set_1[i])\n",
    "    # print(action_set)\n",
    "    \n",
    " \n",
    "    def oracle_action(overhead):\n",
    "        oracle_reward = []\n",
    "        for i in action_set:\n",
    "            o_reward = 0 \n",
    "            for t in range(df.shape[0]):\n",
    "                if c_i_data_thi[t] >= i[0]:\n",
    "                    reward = 0\n",
    "    #                 predictions.append(df[\"Fou_layer_P\"][t])\n",
    "                elif c_i_data_six[t] >= i[1]:\n",
    "                    reward = c_i_data_six[t] -  c_i_data_thi[t] - overhead[0]\n",
    "                else:\n",
    "                    reward = c_l_data[t] - c_i_data_thi[t] - overhead[0] - overhead[1]\n",
    "                o_reward += reward\n",
    "    #         print(oracle_reward)\n",
    "            oracle_reward.append(o_reward/df.shape[0])\n",
    "\n",
    "        return oracle_reward.index(max(oracle_reward)), oracle_reward\n",
    "    oracle_action, o_reward = oracle_action(overhead)\n",
    "    \n",
    "    \n",
    "    print(\"Oracle action =====> \", oracle_action)\n",
    "    \n",
    "    \n",
    "    preds = []\n",
    "    count = 0\n",
    "    oracle_reward = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if c_i_data_thi[i] > action_set[oracle_action][0]:\n",
    "            reward = 0\n",
    "            count += 1\n",
    "            preds.append(df[\"Thi_layer_P\"][i])\n",
    "            oracle_reward.append(reward)\n",
    "        elif c_i_data_six[i] >= action_set[oracle_action][1]:\n",
    "            reward = c_i_data_six[i] -  c_i_data_thi[i] - overhead[0]\n",
    "            preds.append(df[\"Six_layer_P\"][i])\n",
    "            oracle_reward.append(reward)\n",
    "        else:\n",
    "            preds.append(df[\"Last_layer\"][i])\n",
    "            reward = c_l_data[i] - c_i_data_thi[i] - overhead[0] - overhead[1]\n",
    "            oracle_reward.append(reward)\n",
    "    \n",
    "    \n",
    "#     action = random.choice(action_set)\n",
    "    print(\"Action is \", action)\n",
    "    \n",
    "#     preds = []\n",
    "#     count_1 = 0\n",
    "    rewards = []\n",
    "    for i in range(df.shape[0]):\n",
    "        \n",
    "        if c_i_data_thi[i] >= action[0]:\n",
    "            reward = 0\n",
    "#                 count_1 += 1\n",
    "            preds.append(df[\"Thi_layer_P\"][i])\n",
    "            rewards.append(reward)\n",
    "        elif c_i_data_six[i] >= action[1]:\n",
    "            reward = c_i_data_six[i] - c_i_data_thi[i] - overhead[0]\n",
    "#                 count_1 += 1\n",
    "            preds.append(df[\"Six_layer_P\"][i])\n",
    "            rewards.append(reward)\n",
    "        else:\n",
    "            preds.append(df[\"Last_layer\"][i])\n",
    "            reward = c_l_data[i] - c_i_data_thi[i] - overhead[0] - overhead[1]\n",
    "            rewards.append(reward)\n",
    "    \n",
    "                \n",
    "    oracle_reward = np.array(oracle_reward)\n",
    "    rewards = np.array(rewards)\n",
    "    regret = (oracle_reward-rewards)\n",
    "    cumulative_regret = abs(np.cumsum(regret))\n",
    "    # print(oracle_reward,'\\n', rewards)\n",
    "    \n",
    "    \n",
    "    return cumulative_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lis_3 = []\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    df = df.sample(frac = 1)\n",
    "    cum_reg_3 = one_action_cycle(df, action_set, [0.5, 0.5], overhead = [0.06, 0.04])  \n",
    "    reg_lis_3.append([cum_reg_3[j] for j in idx])\n",
    "    \n",
    "reg_lis_3 = np.array(reg_lis_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_lis_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_3 = []\n",
    "upper_3 = []\n",
    "\n",
    "for i in range(len(reg_lis[0])):\n",
    "    intrval = st.t.interval(alpha=0.95, df=len(reg_lis_3[:,i])-1,\n",
    "              loc=np.mean(reg_lis_3[:,i]),\n",
    "              scale=st.sem(reg_lis_3[:,i]))\n",
    "\n",
    "        \n",
    "    lower_3.append(intrval[0])\n",
    "    upper_3.append(intrval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lower_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\alpha = 0.8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lis_4 = []\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    df = df.sample(frac = 1)\n",
    "    cum_reg_4 = one_action_cycle(df, action_set, [0.8, 0.8], overhead = [0.06, 0.04])\n",
    "\n",
    "        \n",
    "    reg_lis_4.append([cum_reg_4[j] for j in idx])\n",
    "    \n",
    "reg_lis_4 = np.array(reg_lis_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_lis_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_4 = []\n",
    "lower_4 = []\n",
    "\n",
    "for i in range(len(reg_lis[0])):\n",
    "    intrval = st.t.interval(alpha=0.95, df=len(reg_lis_4[:,i])-1,\n",
    "              loc=np.mean(reg_lis_4[:,i]),\n",
    "              scale=st.sem(reg_lis_4[:,i]))\n",
    "        \n",
    "    lower_4.append(intrval[0])\n",
    "    upper_4.append(intrval[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\alpha = 0.9$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lis_5 = []\n",
    "for i in range(num_cycles):\n",
    "    df = df.sample(frac = 1)\n",
    "    cum_reg_5 = one_action_cycle(df, action_set, [0.9, 0.8], overhead = [0.06, 0.04])\n",
    "        \n",
    "    reg_lis_5.append([cum_reg_5[j] for j in idx])\n",
    "    \n",
    "reg_lis_5 = np.array(reg_lis_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_lis_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_5 = []\n",
    "upper_5 = []\n",
    "\n",
    "for i in range(len(reg_lis[0])):\n",
    "    intrval = st.t.interval(alpha=0.95, df=len(reg_lis_5[:,i])-1,\n",
    "              loc=np.mean(reg_lis_5[:,i]),\n",
    "              scale=st.sem(reg_lis_5[:,i]))\n",
    "        \n",
    "    lower_5.append(intrval[0])\n",
    "    upper_5.append(intrval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lower_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Final-Exit$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lis_fin = []\n",
    "for i in range(num_cycles):\n",
    "    df = df.sample(frac = 1)\n",
    "    cum_reg_fin = one_action_cycle(df, action_set, [1.0, 0.9], overhead = [0.06, 0.04])\n",
    "        \n",
    "    reg_lis_fin.append([cum_reg_fin[j] for j in idx])\n",
    "    \n",
    "reg_lis_fin = np.array(reg_lis_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_lis_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fin = []\n",
    "upper_fin = []\n",
    "\n",
    "for i in range(len(reg_lis[0])):\n",
    "    intrval = st.t.interval(alpha=0.95, df=len(reg_lis_fin[:,i])-1,\n",
    "              loc=np.mean(reg_lis_fin[:,i]),\n",
    "              scale=st.sem(reg_lis_fin[:,i]))\n",
    "        \n",
    "    lower_fin.append(intrval[0])\n",
    "    upper_fin.append(intrval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(len(idx))]\n",
    "plt.plot(reg_lis.mean(axis = 0) ,'g', label=\"UBERT\",linestyle = 'solid')\n",
    "plt.fill_between(x, lower, upper, color='green', alpha=0.1)\n",
    "plt.plot(reg_lis_3.mean(axis = 0) ,'orange', label=\"alpha = [0.6, 0.5]\", linestyle = 'dashed')\n",
    "plt.fill_between(x, lower_3, upper_3, color='orange', alpha=0.1)\n",
    "plt.plot(reg_lis_4.mean(axis = 0) ,'red', label=\"alpha = [0.9, 0.8]\", linestyle = 'dashdot')\n",
    "plt.fill_between(x, lower_4, upper_4, color='red', alpha=0.1)\n",
    "plt.plot(reg_lis_5.mean(axis = 0) ,'blue', label=\"alpha = [0.5,0.5]\",linestyle = 'dotted')\n",
    "plt.fill_between(x, lower_5, upper_5, color='blue', alpha=0.1)\n",
    "plt.plot(reg_lis_fin.mean(axis = 0) ,'brown', label=\"alpha = [1.0, 0.9](Final-Exit)\",linestyle = 'dashed')\n",
    "plt.fill_between(x, lower_fin, upper_fin, color='brown', alpha=0.1)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time horizon\")\n",
    "plt.ylabel(\"Cumulative regret\")\n",
    "plt.title(\"IMDb\")\n",
    "plt.savefig('/home/divya/UBERT/Regret_plot_reduced/Regret_plot_imdb.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cycles = 5\n",
    "def accuracy_lat_calcu(df, optimal_action, overhead = [0.06, 0.04]):\n",
    "    c_i_data_thi = []\n",
    "    for i in df[\"PProb_thi\"]:\n",
    "        c_i_data_thi.append(i)\n",
    "\n",
    "    c_i_data_six = []\n",
    "    for i in df[\"PProb_six\"]:\n",
    "        c_i_data_six.append(i)\n",
    "\n",
    "    c_l_data = []\n",
    "    for i in df[\"PProb_las\"]:\n",
    "        c_l_data.append(i)\n",
    "\n",
    "    preds = []\n",
    "    count_1 = 0\n",
    "    count_2 = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        \n",
    "        if c_i_data_thi[i] >= optimal_action[0]:\n",
    "            # reward = 0\n",
    "            count_1+=1\n",
    "#                 count_1 += 1\n",
    "            preds.append(df[\"Thi_layer_P\"][i])\n",
    "        elif c_i_data_six[i] >= optimal_action[1]:\n",
    "            # reward = c_i_data_six[i] - c_i_data_thi[i] - overhead[0]\n",
    "            count_2+=1  \n",
    "            preds.append(df[\"Six_layer_P\"][i])\n",
    "            # rewards.append(reward)\n",
    "        else:\n",
    "            preds.append(df[\"Last_layer\"][i])\n",
    "            # reward = c_l_data[i] - c_i_data_thi[i] - overhead[0] - overhead[1]\n",
    "            # rewards.append(reward)\n",
    "    accuracy = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        if preds[i] == df[\"True_labels\"][i]:\n",
    "            accuracy+=1\n",
    "        else:\n",
    "            pass\n",
    "    return accuracy/df.shape[0], count_1/df.shape[0], count_2/df.shape[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cycles = 5\n",
    "accuracy_lis = []\n",
    "latency_lis = []\n",
    "for i in range(num_cycles):\n",
    "    df = df.sample(frac = 1)\n",
    "    _,_,_,optimal_action = one_cycle(df, action_set, overhead = [0.06, 0.04])\n",
    "    accuracy, count_1, count_2 = accuracy_lat_calcu(df, optimal_action, overhead = [0.06, 0.04])\n",
    "    latency = count_1+count_2\n",
    "    print(\"Optimal action is:\", optimal_action,\n",
    "          \"\\n=============================\\n Fraction of Exits at first layer\",count_1,\n",
    "          \"\\n=============================\\n Fraction of Exits at second layer\", count_2,\n",
    "          \"\\n=============================\\n Total latency\", 1-(count_1+count_2)\n",
    "              )\n",
    "    accuracy_lis.append(accuracy)\n",
    "    latency_lis.append(latency)\n",
    "accuracy_lis = np.array(accuracy_lis)\n",
    "latency_lis = np.array(latency_lis)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(accuracy_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(latency_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "j_ceebert",
   "language": "python",
   "name": "j_ceebert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
